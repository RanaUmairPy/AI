{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e834fac-3be7-4007-8170-da70ae6a8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from googletrans import Translator\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# initialize\n",
    "stemmer = PorterStemmer()\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20bb0000-64b1-41e7-977f-be84409a51e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Umair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet') \n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37848026-3d80-4e3a-8b93-1143136c2598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre Urdu Word پڑھنا\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "پڑھنا into English -> Read\n"
     ]
    }
   ],
   "source": [
    "x = input(\"Entre Urdu Word\")\n",
    "result = translator.translate(x, src='ur', dest='en')\n",
    "word = result.text\n",
    "\n",
    "print(x+\" into English -> \"+word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3bc179-3b32-49be-b897-bfdea6ca4c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['read',\n",
       " 'say',\n",
       " 'scan',\n",
       " 'take',\n",
       " 'learn',\n",
       " 'study',\n",
       " 'register',\n",
       " 'show',\n",
       " 'record',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'translate']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1 Lemmas\n",
    "a = []\n",
    "def fn(sword):\n",
    "\n",
    "    for word in wordnet.synsets(sword):\n",
    "        #print(word)\n",
    "        for x in word.lemmas(): \n",
    "            a.append(x.name())\n",
    "    return a\n",
    "fn(word)\n",
    "\n",
    "#newlist= set(fn(word))\n",
    "\n",
    "#duplicate remove\n",
    "lema_list = []\n",
    "for i in range(len(a)):\n",
    "    if a[i] not in lema_list:\n",
    "        lema_list.append(a[i])\n",
    "lema_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1290280c-db20-4c0b-ad82-72d56c620f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['read',\n",
       " 'say',\n",
       " 'scan',\n",
       " 'take',\n",
       " 'learn',\n",
       " 'studi',\n",
       " 'regist',\n",
       " 'show',\n",
       " 'record',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'translat']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2 stemming\n",
    "stem_list = []\n",
    "def stem(word):\n",
    "    for i in range(len(word)):\n",
    "          temp = stemmer.stem(word[i])\n",
    "          stem_list.append(temp)\n",
    "stem(lema_list)   \n",
    "stem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a56e9bbd-d60d-4184-a6dc-5d68939c492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['پڑھیں',\n",
       " 'کہو',\n",
       " 'اسکین',\n",
       " 'لے',\n",
       " 'سیکھیں',\n",
       " 'اسٹوڈی',\n",
       " 'رجسٹر',\n",
       " 'دکھائیں',\n",
       " 'ریکارڈ',\n",
       " 'سمجھنا',\n",
       " 'تشریح کریں',\n",
       " 'ترجمہ کریں']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdulist = []\n",
    "for i in range(len(stem_list)):\n",
    "         list = translator.translate(stem_list[i], dest='ur',src='en')\n",
    "         urdulist.append(list.text)\n",
    "urdulist        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a075c90a-b5d7-4362-8f42-8615eff79c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['يقرأ',\n",
       " 'يقول',\n",
       " 'مسح',\n",
       " 'يأخذ',\n",
       " 'يتعلم',\n",
       " 'Studi',\n",
       " 'ريجست',\n",
       " 'يعرض',\n",
       " 'سِجِلّ',\n",
       " 'يفهم',\n",
       " 'يفسر',\n",
       " 'يترجم']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Arbiclist = []\n",
    "for i in range(len(stem_list)):\n",
    "         list = translator.translate(stem_list[i], dest='ar',src='en')\n",
    "         Arbiclist.append(list.text)\n",
    "Arbiclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254474be-444a-4c9e-8833-cace99a5e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from nltk.corpus import wordnet\n",
    "\n",
    "# Example word\n",
    "word = \"run\"  # Replace with any word\n",
    "\n",
    "# Print all synsets for the word\n",
    "synsets = wordnet.synsets(word)\n",
    "print(\"Synsets for the word:\", word)\n",
    "for synset in synsets:\n",
    "    print(synset)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2416eb10-18af-4f1a-8c75-8def7aed2958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Umair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['record', 'phonograph_record', 'phonograph_recording', 'record', 'disk', 'disc', 'platter', 'record', 'record', 'track_record', 'record', 'record_book', 'book', 'record', 'record', 'criminal_record', 'record', 'record', 'enter', 'put_down', 'record', 'tape', 'read', 'register', 'show', 'record', 'record', 'register', 'commemorate', 'memorialize', 'memorialise', 'immortalize', 'immortalise', 'record']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ریکارڈ',\n",
       " 'فونگراف_ریکورڈ',\n",
       " 'فونگراف_رکارڈنگ',\n",
       " 'ریکارڈ',\n",
       " 'ڈسک',\n",
       " 'ڈسک',\n",
       " 'پلیٹر',\n",
       " 'ریکارڈ',\n",
       " 'ریکارڈ',\n",
       " 'ٹریک_ریکورڈ',\n",
       " 'ریکارڈ',\n",
       " 'ریکارڈ_بک',\n",
       " 'کتاب',\n",
       " 'ریکارڈ',\n",
       " 'ریکارڈ',\n",
       " 'مجرمانہ_ریکورڈ',\n",
       " 'ریکارڈ',\n",
       " 'ریکارڈ',\n",
       " 'داخل کریں',\n",
       " 'put_down',\n",
       " 'ریکارڈ',\n",
       " 'ٹیپ',\n",
       " 'پڑھیں',\n",
       " 'رجسٹر کریں',\n",
       " 'دکھائیں',\n",
       " 'ریکارڈ',\n",
       " 'ریکارڈ',\n",
       " 'رجسٹر کریں',\n",
       " 'یادگاری',\n",
       " 'یادگار',\n",
       " 'یادگار',\n",
       " 'لافانی بنائیں',\n",
       " 'لافانی',\n",
       " 'ریکارڈ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from googletrans import Translator\n",
    "nltk.download('wordnet') \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "def get_urdu_synonyms(urdu_word):\n",
    "    eng_list = []\n",
    "    translated_word = translator.translate(urdu_word, src=\"ur\", dest=\"en\").text\n",
    "    \n",
    "  \n",
    "    for word in wordnet.synsets(translated_word):\n",
    "              for j in word.lemmas():\n",
    "                   eng_list.append(j.name())\n",
    "              \n",
    "           \n",
    "\n",
    "   \n",
    "    urdu_synonyms = [translator.translate(word, src=\"en\", dest=\"ur\").text for word in eng_list]\n",
    "    print(eng_list)\n",
    "    return urdu_synonyms\n",
    "\n",
    "\n",
    "urdu_word = \"ریکارڈ\"  \n",
    "get_urdu_synonyms(urdu_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a7ea67e-30e8-4a46-8e0c-b380bf4ca577",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urdu_synonyms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43murdu_synonyms\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'urdu_synonyms' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e34636-bac1-443d-bc86-2840ea7428b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cb4c8-68a1-4d95-bde5-73c6ad82bb28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
