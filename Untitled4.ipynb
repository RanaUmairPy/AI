{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b771655-e57a-4897-ad9f-593f3b8ad51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119b09bd-33dd-4deb-9600-a3faba3bfd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1.csv')\n",
    "x = df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee5b501-6835-43c2-a857-cdd706d481fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"BBC News - Amazon boss Jeff Bezos rejects claims company acted like a 'drug dealer' bbc.co.uk/news/av/busine‚Ä¶\",\n",
       " '@Microsoft Why do I pay for WORD when it functions so poorly on my @SamsungUS Chromebook? üôÑ',\n",
       " \"CSGO matchmaking is so full of closet hacking, it's a truly awful game.\",\n",
       " 'Now the President is slapping Americans in the face that he really did commit an unlawful act after his acquittal! From Discover on Google vanityfair.com/news/2020/02/t‚Ä¶',\n",
       " 'Hi @EAHelp I‚Äôve had Madeleine McCann in my cellar for the past 13 years and the little sneaky thing just escaped whilst I was loading up some FIFA points, she took my card, and I‚Äôm having to use my PayPal account, but it isn‚Äôt working, can you help me resolve it please?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------spelling and correcting------------------------\n",
    "import language_tool_python as ltp\n",
    "\n",
    "tool = ltp.LanguageTool('en-US')\n",
    "a = []\n",
    "for i in range(5):\n",
    "    text = x.iloc[i]\n",
    "    text_join = ''.join(text)\n",
    "    matches = tool.check(text_join)\n",
    "    corect_text = ltp.utils.correct(text_join,matches)\n",
    "    a.append(corect_text)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10a63ec-4c4f-4954-b2b7-08628a2bc9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match({'ruleId': 'I_LOWERCASE', 'message': 'The personal pronoun ‚ÄúI‚Äù should be uppercase.', 'replacements': ['I'], 'offsetInContext': 0, 'context': 'i am studnyt, i lke pytoon', 'offset': 0, 'errorLength': 1, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'i am studnyt, i lke pytoon'}),\n",
       " Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['student', 'study', 'stunt', 'studly'], 'offsetInContext': 5, 'context': 'i am studnyt, i lke pytoon', 'offset': 5, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'i am studnyt, i lke pytoon'}),\n",
       " Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['like', 'lake', 'Lee', 'lie', 'Luke', 'lye', 'eke', 'LTE', 'AKE', 'BKE', 'Ike', 'KE', 'LBE', 'LDE', 'LE', 'LKA', 'LKM', 'LME', 'LNE', 'LPE', 'LSE', 'Le', 'Lie', 'lee', 'GKE'], 'offsetInContext': 16, 'context': 'i am studnyt, i lke pytoon', 'offset': 16, 'errorLength': 3, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'i am studnyt, i lke pytoon'}),\n",
       " Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Python', 'python'], 'offsetInContext': 20, 'context': 'i am studnyt, i lke pytoon', 'offset': 20, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'i am studnyt, i lke pytoon'})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------spelling and correcting------------------------\n",
    "import language_tool_python as ltp\n",
    "\n",
    "tool = ltp.LanguageTool('en-US')\n",
    "\n",
    "\n",
    "text_join = 'i am studnyt, i lke pytoon'\n",
    "matches = tool.check(text_join)\n",
    "corect_text = ltp.utils.correct(text_join,matches)\n",
    "corect_text\n",
    "matches\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d7d77c4-743f-41fd-b49f-2217ade449d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@', 'PUNCT'),\n",
       " ('Microsoft', 'PROPN'),\n",
       " ('Why', 'SCONJ'),\n",
       " ('do', 'AUX'),\n",
       " ('I', 'PRON'),\n",
       " ('pay', 'VERB'),\n",
       " ('for', 'ADP'),\n",
       " ('WORD', 'PROPN'),\n",
       " ('when', 'SCONJ'),\n",
       " ('it', 'PRON'),\n",
       " ('functions', 'VERB'),\n",
       " ('so', 'ADV'),\n",
       " ('poorly', 'ADV'),\n",
       " ('on', 'ADP'),\n",
       " ('my', 'PRON'),\n",
       " ('@', 'NOUN'),\n",
       " ('SamsungUS', 'PROPN'),\n",
       " ('Chromebook', 'PROPN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('üôÑ', 'NOUN')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------POS ENGLISH--------------------------------------\n",
    "import spacy\n",
    "import nltk\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokens = x.apply(nltk.word_tokenize)\n",
    "finallist = []\n",
    "for i in range(5):\n",
    "    tweet = ' '.join(tokens[i])\n",
    "    doc = nlp(tweet)\n",
    "    finallist.append([(token.text,token.pos_) for token in doc])\n",
    "finallist[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe56f2df-1502-486a-9f54-cba80514fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f558f62068aa4b898e0dcb1d61e08e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded file to C:\\Users\\Umair\\stanza_resources\\resources.json\n",
      "Loading these models for language: ur (Urdu):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | udtb          |\n",
      "| pos       | udtb_nocharlm |\n",
      "| lemma     | udtb_nocharlm |\n",
      "| depparse  | udtb_nocharlm |\n",
      "=============================\n",
      "\n",
      "Using device: cpu\n",
      "Loading: tokenize\n",
      "Loading: pos\n",
      "Loading: lemma\n",
      "Loading: depparse\n",
      "Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ PROPN\n",
      "ŸÖ€å⁄∫ ADP\n",
      "ÿ¢ÿ¨ NOUN\n",
      "ŸÖŸàÿ≥ŸÖ NOUN\n",
      "ÿÆŸàÿ¥⁄ØŸàÿßÿ± ADJ\n",
      "€Å€í AUX\n",
      "€î PUNCT\n"
     ]
    }
   ],
   "source": [
    "#------------------Urdu POS-----------------------------\n",
    "import stanza\n",
    "nlp = stanza.Pipeline('ur')\n",
    "text = \"Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ŸÖ€å⁄∫ ÿ¢ÿ¨ ŸÖŸàÿ≥ŸÖ ÿÆŸàÿ¥⁄ØŸàÿßÿ± €Å€í€î\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(word.text,word.upos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b71b23-c4c4-42e2-8800-b73d4bfb65ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match({'ruleId': 'I_LOWERCASE', 'message': 'The personal pronoun ‚ÄúI‚Äù should be uppercase.', 'replacements': ['I'], 'offsetInContext': 0, 'context': 'i am studnyt, i lke pytoon', 'offset': 0, 'errorLength': 1, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'i am studnyt, i lke pytoon'}),\n",
       " Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['student', 'study', 'stunt', 'studly'], 'offsetInContext': 5, 'context': 'i am studnyt, i lke pytoon', 'offset': 5, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'i am studnyt, i lke pytoon'}),\n",
       " Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['like', 'lake', 'Lee', 'lie', 'Luke', 'lye', 'eke', 'LTE', 'AKE', 'BKE', 'Ike', 'KE', 'LBE', 'LDE', 'LE', 'LKA', 'LKM', 'LME', 'LNE', 'LPE', 'LSE', 'Le', 'Lie', 'lee', 'GKE'], 'offsetInContext': 16, 'context': 'i am studnyt, i lke pytoon', 'offset': 16, 'errorLength': 3, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'i am studnyt, i lke pytoon'}),\n",
       " Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Python', 'python'], 'offsetInContext': 20, 'context': 'i am studnyt, i lke pytoon', 'offset': 20, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'i am studnyt, i lke pytoon'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480e42d-168e-49be-8aa5-4e7b909b4601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
